5.5.1 科研方法
-----------------------

1. 要认识到某种神经网络的本质机制，才能对应的提出这种类型网络的优势和缺点；
   在应用这种方法到某个领域时，要清楚该方法在这个领域问题中的优势和劣势，据此
   实现高水准的迁移应用，针对劣势才可以提出合适的改进方法。

2. 对于一个概念，可以从多个角度被提出和解释，实现一致的功能；

5.5.2 概念见解
-------------------------

1. 胶囊网络 & CNN
   
   * **思路：**
         * 最终分类结果不使用标量构成的向量，而是向量构成的矩阵【使用一个向量的模长表示概率；向量表示一个实例，进而可以重构】
         * 注意局部和整体关系的链接【卷积相当于滤波器过滤了一遍，从整个图像上获取了各个局部的特征信息，但是并没有链接局部和整体的关系，
           这样做导致的结果是，拥有特定类别细节特征的“重组异类”可以轻松被识别为同类，这就造成了漏洞。“局部整体关系”可以类比“时间序列的时序关系“。
           考虑一个问题，首先要考虑整体的关系，然后考虑细节的问题才不会出错；不能只考虑细节。】

2. 协议路由的胶囊网络 & 注意力机制 & Transformer
   
   * **思路：**
         * 网络连接权值的训练问题。【以往都是误差反向传播，没有人为加入一些设计，只是误差梯度导向的；
           但是考虑局部整体关系后，加入了“局部整体”导向的参数训练，提出了“协议路由”的概念，使用内积表示局部和整体的关系，内积越大“路由权值”越大】 

3. Transformer
   
   * **思路：**
         * 键，值，嵌入向量

4. 胶囊网络
   
   * **思路：**
         * 分离不变性  和   等变（姿态）学习机制

5. FLAN（fine-tuned language net）
   
   * **思路：**
         * NLP模型，与GPT-3对比，有更少的参数，更高的性能；
         * 以往的参数越多，能解决更复杂问题的默认概念 是否没有问题？
         * 少量训练数据可用，将知识迁移到新任务的预训练模型；数据过度过滤会降低于洋模型性能。
         * 数据集的丰富多样性